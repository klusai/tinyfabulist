## Translation Evaluation Averages

| Model | Translation Accuracy | Fluency | Style Preservation | Moral Clarity | Average Score (Mean) | Count | Avg Input Tokens | Avg Output Tokens | Avg Inference Time (s) |
|-------|---------------------|---------|-------------------|---------------|-----------------|-------|-----------------|------------------|------------------------|
| Llama-3.1-8B-Instruct_deepl | 8.14 | 8.37 | 8.23 | 8.89 | 8.41 | 100 | 141.5 | 350.6 | 101.69 |
| _Enhanced-Llama-3.3-70B | 8.29 | 8.29 | 8.29 | 8.92 | 8.45 | 100 | 141.5 | 350.6 | 101.69 |
| Llama-3.1-8B-Instruct_gpt-4o | 8.64 | 8.55 | 8.62 | 9.24 | 8.76 | 100 | 141.5 | 350.6 | 101.69 |
| Llama-3.1-8B-Instruct_Llama-3.3-70B-Instruct | 7.52 | 7.83 | 7.67 | 8.67 | 7.92 | 100 | 141.5 | 350.6 | 101.69 |
| _Enhanced-Llama-3.3-70B_Fine_Prompted | 7.89 | 8.18 | 8.16 | 8.87 | 8.28 | 100 | 141.5 | 350.6 | 101.69 |
