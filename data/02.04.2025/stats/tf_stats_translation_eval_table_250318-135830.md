## Translation Evaluation Averages

| Model | Translation Accuracy | Fluency | Style Preservation | Moral Clarity | Average Score (Mean) | Count | Avg Input Tokens | Avg Output Tokens | Avg Inference Time (s) |
|-------|---------------------|---------|-------------------|---------------|-----------------|-------|-----------------|------------------|------------------------|
| Llama-3.1-8B-Instruct_deepl | 8.19 | 8.36 | 8.26 | 8.92 | 8.43 | 100 | 141.5 | 350.6 | 101.69 |
| Llama-3.1-8B-Instruct_gpt-4o | 8.63 | 8.61 | 8.70 | 9.17 | 8.78 | 100 | 141.5 | 350.6 | 101.69 |
| Llama-3.1-8B-Instruct_Llama-3.1-8B-Instruct | 3.98 | 4.48 | 4.25 | 5.56 | 4.57 | 100 | 141.5 | 350.6 | 101.69 |
| Llama-3.1-8B-Instruct_Llama-3.3-70B-Instruct | 7.40 | 7.76 | 7.71 | 8.71 | 7.90 | 100 | 141.5 | 350.6 | 101.69 |
| Llama-3.1-8B-Instruct_o3-mini-2025-01-31 | 8.42 | 8.37 | 8.44 | 9.13 | 8.59 | 100 | 141.5 | 350.6 | 101.69 |
| _Enhanced-Llama-3.3-70B | 6.92 | 7.57 | 7.37 | 5.01 | 6.72 | 100 | 141.5 | 350.6 | 101.69 |
