## Evaluation Averages

| Model | Grammar | Creativity | Moral Clarity | Adherence to Prompt | Average Score (Mean) | Count | Avg Input Tokens | Avg Output Tokens | Avg Inference Time (s) |
|-------|---------|------------|---------------|---------------------|----------------------|-------|------------------|-------------------|------------------------|

| SmolLM2-1.7B-Instruct | 7.94 | 5.82 | 7.49 | 5.05 | 6.58 | 100 | 137.3 | 415.8 | 26.28 |
| aya-23-8B | 8.22 | 6.33 | 7.81 | 6.15 | 7.13 | 100 | 134.8 | 472.6 | 373.23 |
| Llama-3.1-8B-Instruct | 8.69 | 7.23 | 8.47 | 8.70 | 8.27 | 100 | 141.5 | 346.1 | 44.64 |
| Llama-3.2-1B-Instruct | 8.12 | 6.05 | 7.03 | 5.54 | 6.68 | 100 | 141.5 | 378.4 | 22.50 |
| Mistral-7B-Instruct-v0.3 | 8.77 | 7.18 | 8.80 | 8.53 | 8.32 | 100 | 159.1 | 469.6 | 51.33 |
| Qwen2.5-7B | 8.25 | 5.91 | 7.75 | 5.58 | 6.87 | 100 | 142.6 | 487.3 | 37.82 |
| deepseek-llm-7b-chat | 8.33 | 6.41 | 8.08 | 6.72 | 7.38 | 100 | 149.3 | 494.9 | 90.26 |
| Phi-3-mini-4k-instruct  | 8.59 | 7.20 | 8.47 | 8.03 | 8.07 | 100 | 0.0 | 0.0 | 37.91 |
| Qwen2.5-7B-Instruct | 8.53 | 7.07 | 8.57 | 7.67 | 7.96 | 100 | 142.6 | 482.3 | 24.02 |
| Falcon3-7B-Instruct | 8.88 | 7.56 | 8.89 | 8.95 | 8.57 | 100 | 145.2 | 430.4 | 42.41 |