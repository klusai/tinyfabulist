## Translation Evaluation Averages

| Model | Translation Accuracy | Fluency | Style Preservation | Moral Clarity | Average Score (Mean) | Count | Avg Input Tokens | Avg Output Tokens | Avg Inference Time (s) |
|-------|----------------------|---------|--------------------|---------------|----------------------|-------|------------------|-------------------|------------------------|

| Llama-3.1-Tulu-3-8B_gpt-4.1-mini-2025-04-14 | 8.36 | 8.38 | 8.58 | 9.66 | 8.75 | 100 | 181.5 | 368.5 | 16.91 |
| Llama-3.1-8B-Instruct | 7.45 | 7.80 | 7.06 | 8.74 | 7.76 | 200 | 181.7 | 337.5 | 92.70 |
| Llama-3.1-Tulu-3-8B_gpt-4.1-nano-2025-04-14 | 6.87 | 6.84 | 7.24 | 8.72 | 7.42 | 100 | 181.5 | 368.5 | 16.91 |
| Llama-3.1-Tulu-3-8B_gpt-4.1-2025-04-14 | 8.90 | 8.80 | 8.92 | 9.71 | 9.08 | 100 | 181.5 | 368.5 | 16.91 |