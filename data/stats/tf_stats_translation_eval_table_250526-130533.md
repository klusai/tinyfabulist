## Translation Evaluation Averages

| Model | Accuracy | Fluency | Coherence | Style | Cultural/Pragmatic | Average Score | Count | Avg Input Tokens | Avg Output Tokens | Avg Inference Time (s) |
|-------|----------|---------|-----------|-------|-------------------|--------------|-------|------------------|-------------------|------------------------|

| deepl | 4.43 | 4.76 | 4.43 | 4.71 | 4.77 | 4.62 | 100 | 181.3 | 342.7 | 20.37 |
| gpt-4.1-2025-04-14 | 4.81 | 4.92 | 4.91 | 4.90 | 4.94 | 4.90 | 100 | 181.3 | 342.7 | 20.37 |
| gpt-4.1-mini-2025-04-14 | 4.58 | 4.73 | 4.81 | 4.85 | 4.87 | 4.77 | 100 | 181.3 | 342.7 | 20.37 |
| gemma-3-12b-it | 4.03 | 4.45 | 4.60 | 4.45 | 4.46 | 4.40 | 100 | 0.0 | 0.0 | 0.00 |
| EuroLLM-9B-Instruct | 3.76 | 4.19 | 4.32 | 4.17 | 4.07 | 4.10 | 99 | 0.0 | 0.0 | 0.00 |