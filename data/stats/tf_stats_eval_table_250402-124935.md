## Evaluation Averages

| Model | Grammar | Creativity | Moral Clarity | Adherence to Prompt | Average Score (Mean) | Count | Avg Input Tokens | Avg Output Tokens | Avg Inference Time (s) |
|-------|---------|------------|---------------|---------------------|----------------------|-------|------------------|-------------------|------------------------|

| aya-23-8B | 7.78 | 5.75 | 7.24 | 5.12 | 6.47 | 100 | 171.8 | 500.6 | 257.89 |
| Llama-3.1-Tulu-3-8B | 8.32 | 6.97 | 8.50 | 7.69 | 7.87 | 100 | 181.5 | 368.5 | 16.91 |
| Falcon3-7B-Instruct | 8.29 | 6.56 | 8.27 | 7.06 | 7.54 | 100 | 186.2 | 400.4 | 20.72 |
| Qwen2.5-7B-Instruct | 8.28 | 6.21 | 8.02 | 6.81 | 7.33 | 100 | 182.6 | 404.2 | 17.72 |
| Phi-3-mini-4k-instruct  | 8.10 | 6.28 | 7.87 | 6.61 | 7.21 | 100 | 0.0 | 0.0 | 40.76 |
| deepseek-llm-7b-chat | 8.04 | 6.08 | 7.88 | 5.72 | 6.93 | 100 | 189.3 | 439.8 | 82.36 |
| SmolLM2-1.7B-Instruct | 7.79 | 5.40 | 6.98 | 4.81 | 6.25 | 100 | 174.3 | 414.7 | 17.58 |
| Mistral-7B-Instruct-v0.3 | 8.12 | 6.31 | 8.05 | 6.58 | 7.26 | 100 | 201.1 | 426.4 | 40.70 |
| Llama-3.1-8B-Instruct | 8.42 | 6.59 | 8.21 | 8.18 | 7.85 | 100 | 181.5 | 337.6 | 28.87 |
| Llama-3.2-1B-Instruct | 7.87 | 5.41 | 6.56 | 4.98 | 6.21 | 100 | 181.5 | 358.5 | 16.69 |