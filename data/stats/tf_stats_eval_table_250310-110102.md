## Evaluation Averages
| Model | Grammar | Creativity | Moral Clarity | Adherence to Prompt | Average Score (Mean) | Count | Avg Input Tokens | Avg Output Tokens | Avg Inference Time (s) |
|-------|---------|------------|---------------|---------------------|-----------------|-------|-----------------|------------------|------------------------|
| Llama-3.1-8B-Instruct_gpt-4o_gpt-4o_gpt-4o | 8.66 | 7.68 | 8.56 | 8.03 | 8.23 | 100 | 141.5 | 350.6 | 101.69 |
| Llama-3.1-8B-Instruct-gpt-o3-mini | 8.50 | 7.60 | 8.46 | 7.86 | 8.11 | 100 | 141.5 | 350.6 | 101.69 |
| Llama-3.1-8B-Instruct_gpt-llama-3-1-8b | 7.37 | 6.42 | 7.39 | 5.75 | 6.73 | 100 | 141.5 | 350.6 | 101.69 |
| Llama-3.1-8B-Instruct_deepl | 8.43 | 7.42 | 8.35 | 7.25 | 7.86 | 100 | 141.5 | 346.1 | 44.64 |
