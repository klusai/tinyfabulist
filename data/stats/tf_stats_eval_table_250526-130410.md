## Evaluation Averages

| Model | Grammar | Creativity | Moral Clarity | Adherence to Prompt | Average Score (Mean) | Count | Avg Input Tokens | Avg Output Tokens | Avg Inference Time (s) |
|-------|---------|------------|---------------|---------------------|----------------------|-------|------------------|-------------------|------------------------|

| Llama-3.1-8B-Instruct_deepl | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 100 | 181.3 | 342.7 | 20.37 |
| Llama-3.1-8B-Instruct_gpt-4.1-2025-04-14 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 100 | 181.3 | 342.7 | 20.37 |
| Llama-3.1-8B-Instruct_gpt-4.1-mini-2025-04-14 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 100 | 181.3 | 342.7 | 20.37 |
| gemma-3-12b-it | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 100 | 0.0 | 0.0 | 0.00 |
| EuroLLM-9B-Instruct | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 99 | 0.0 | 0.0 | 0.00 |