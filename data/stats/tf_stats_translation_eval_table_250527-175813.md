## Translation Evaluation Averages

| Model | Accuracy | Fluency | Coherence | Style | Cultural/Pragmatic | Average Score | Count | Avg Input Tokens | Avg Output Tokens | Avg Inference Time (s) |
|-------|----------|---------|-----------|-------|-------------------|--------------|-------|------------------|-------------------|------------------------|

| gemini-flash-1.5-8b | 4.14 | 4.45 | 4.67 | 4.52 | 4.46 | 4.45 | 99 | 181.3 | 342.6 | 20.40 |
| gemini-2.0-flash-001 | 4.66 | 4.82 | 4.78 | 4.89 | 4.93 | 4.82 | 100 | 181.3 | 342.7 | 20.37 |
| deepl | 4.42 | 4.73 | 4.38 | 4.69 | 4.74 | 4.59 | 100 | 181.3 | 342.7 | 20.37 |
| gpt-4.1-2025-04-14 | 4.86 | 4.89 | 4.85 | 4.92 | 4.94 | 4.89 | 100 | 181.3 | 342.7 | 20.37 |
| EuroLLM-9B-Instruct | 3.84 | 4.27 | 4.36 | 4.27 | 4.22 | 4.19 | 98 | 0.0 | 0.0 | 0.00 |
| gpt-4.1-mini-2025-04-14 | 4.54 | 4.71 | 4.72 | 4.84 | 4.83 | 4.73 | 98 | 181.3 | 342.2 | 20.35 |
| gemini-2.5-flash-preview-05-20 | 4.75 | 4.86 | 4.82 | 4.87 | 4.89 | 4.84 | 100 | 181.3 | 342.7 | 20.37 |
| grok-3-mini-beta | 4.73 | 4.74 | 4.77 | 4.82 | 4.88 | 4.79 | 100 | 181.3 | 342.7 | 20.37 |
| gemma-3-12b-it | 3.98 | 4.56 | 4.65 | 4.52 | 4.43 | 4.43 | 100 | 0.0 | 0.0 | 0.00 |