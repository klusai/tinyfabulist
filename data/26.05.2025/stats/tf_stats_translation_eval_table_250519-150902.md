## Translation Evaluation Averages

| Model | Translation Accuracy | Fluency | Style Preservation | Moral Clarity | Average Score (Mean) | Count | Avg Input Tokens | Avg Output Tokens | Avg Inference Time (s) |
|-------|----------------------|---------|--------------------|---------------|----------------------|-------|------------------|-------------------|------------------------|

| Llama-3.1-Tulu-3-8B_gpt-4.1-mini-2025-04-14 | 8.36 | 8.38 | 8.58 | 9.66 | 8.75 | 100 | 181.5 | 368.5 | 16.91 |
| Llama-3.1-8B-Instruct | 7.45 | 7.80 | 7.06 | 8.74 | 7.76 | 200 | 181.7 | 337.5 | 92.70 |
| Llama-3.1-8B-Instruct-Iterational | 7.20 | 7.42 | 6.65 | 8.48 | 7.44 | 115 | 181.9 | 337.5 | 75.15 |
| Gemma3-2Iter | 8.82 | 8.85 | 8.02 | 9.33 | 8.75 | 61 | 181.3 | 338.8 | 57.60 |
| Gemma3 | 8.88 | 8.86 | 8.06 | 9.60 | 8.85 | 108 | 181.8 | 337.7 | 58.07 |
| Llama-3.1-Tulu-3-8B_gpt-4.1-nano-2025-04-14 | 6.87 | 6.84 | 7.24 | 8.72 | 7.42 | 100 | 181.5 | 368.5 | 16.91 |
| Llama-3.1-Tulu-3-8B_gpt-4.1-2025-04-14 | 8.90 | 8.80 | 8.92 | 9.71 | 9.08 | 100 | 181.5 | 368.5 | 16.91 |
| Gemma3-U2iter | 8.89 | 8.99 | 8.12 | 9.59 | 8.90 | 94 | 181.9 | 338.4 | 42.21 |