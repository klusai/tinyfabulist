## Evaluation Averages
| Model | Grammar | Creativity | Moral Clarity | Adherence to Prompt | Average Score (Mean) | Count | Avg Input Tokens | Avg Output Tokens | Avg Inference Time (s) |
|-------|---------|------------|---------------|---------------------|-----------------|-------|-----------------|------------------|------------------------|
| Llama-3.1-8B-Instruct_gpt-4o | 8.51 | 7.58 | 8.64 | 8.20 | 8.23 | 100 | 141.5 | 350.6 | 101.69 |
| Llama-3.1-8B-Instruct_gpt-o3-mini | 8.44 | 7.57 | 8.52 | 8.18 | 8.18 | 100 | 141.5 | 350.6 | 101.69 |
| Llama-3.1-8B-Instruct_llama-3-1-8b | 7.09 | 6.48 | 7.42 | 6.02 | 6.75 | 100 | 141.5 | 350.6 | 101.69 |
| Llama-3.1-8B-Instruct_deepl | 8.29 | 7.40 | 8.46 | 8.09 | 8.06 | 100 | 141.5 | 350.6 | 101.69 |
