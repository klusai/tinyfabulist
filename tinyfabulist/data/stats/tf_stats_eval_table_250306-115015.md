## Evaluation Averages
| Model | Grammar | Creativity | Moral Clarity | Adherence to Prompt | Average Score (Mean) | Count | Avg Input Tokens | Avg Output Tokens | Avg Inference Time (s) |
|-------|---------|------------|---------------|---------------------|-----------------|-------|-----------------|------------------|------------------------|
| Llama-3.1-8B-Instruct | 8.69 | 7.23 | 8.47 | 8.70 | 8.27 | 100 | 141.5 | 346.1 | 44.64 |
| DeepSeek-R1-Distill-Llama-8B | 7.79 | 6.61 | 6.37 | 5.96 | 6.68 | 100 | 141.5 | 955.1 | 94.04 |
| SmolLM2-1.7B-Instruct | 7.94 | 5.82 | 7.49 | 5.05 | 6.58 | 100 | 137.3 | 415.8 | 26.28 |
| Llama-3.2-1B-Instruct | 8.12 | 6.05 | 7.03 | 5.54 | 6.68 | 100 | 141.5 | 378.4 | 22.50 |
| Mistral-7B-Instruct-v0.3 | 8.77 | 7.18 | 8.80 | 8.53 | 8.32 | 100 | 159.1 | 469.6 | 51.33 |
| aya-23-8B | 8.22 | 6.33 | 7.81 | 6.15 | 7.13 | 100 | 134.8 | 472.6 | 373.23 |
