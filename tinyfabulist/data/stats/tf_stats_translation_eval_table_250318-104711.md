## Translation Evaluation Averages

| Model | Translation Accuracy | Fluency | Style Preservation | Moral Clarity | Average Score (Mean) | Count | Avg Input Tokens | Avg Output Tokens | Avg Inference Time (s) |
|-------|---------------------|---------|-------------------|---------------|-----------------|-------|-----------------|------------------|------------------------|
| Llama-3.1-8B-Instruct_deepl | 7.97 | 8.29 | 8.07 | 8.79 | 8.28 | 100 | 141.5 | 350.6 | 101.69 |
| Llama-3.1-8B-Instruct_o3-mini-2025-01-31 | 8.21 | 8.26 | 8.23 | 8.89 | 8.40 | 100 | 141.5 | 350.6 | 101.69 |
| Llama-3.1-8B-Instruct_gpt-4o | 8.52 | 8.46 | 8.50 | 8.98 | 8.62 | 100 | 141.5 | 350.6 | 101.69 |
| Llama-3.1-8B-Instruct_Llama-3.3-70B-Instruct | 7.54 | 7.83 | 7.64 | 8.53 | 7.88 | 100 | 141.5 | 350.6 | 101.69 |
| Llama-3.1-8B-Instruct_Llama-3.1-8B-Instruct | 4.20 | 4.55 | 4.22 | 5.36 | 4.58 | 100 | 141.5 | 350.6 | 101.69 |
